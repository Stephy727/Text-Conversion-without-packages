{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Date: 14/04/2019\n",
    "\n",
    "Environment: Python 3.7.0 and Anaconda3 5.2.0(64-bit)\n",
    "\n",
    "Libraries used:\n",
    "\n",
    "* re 2.2.1 (for regular expression, included in Anaconda Python 3.7.0)\n",
    "* pandas (for dataframe, included in Anaconda Python 3.7.0)\n",
    "* nltk (for text processing)\n",
    "* itertools (for converting dictionary values to list)\n",
    "\n",
    "## 1. Introduction\n",
    "This assessment involves converting unit information into numerical representation suitable as input for various systems such as  recommender system or for information retrieval system. \n",
    "\n",
    "The rules to be followed are:\n",
    "\n",
    "1. The word tokenization must use the following regular expression, \"\\w+(?:[-']\\w+)?\"\n",
    "2. The context-independent and context-dependent (with the threshold set to %95) stop words must be removed from the vocab. The stop words list (i.e, stopwords_en.txt )provided in the zip file must be used.\n",
    "3. Tokens should be stemmed using the Porter stemmer.\n",
    "4. Rare tokens (with the threshold set to %5) must be removed from the vocab.\n",
    "5. Tokens must be normalized to lowercase except the capital tokens appeared in the middle of a sentence/line.\n",
    "6. Tokens with the length less than 3 should be removed from the vocab.\n",
    "7. First 200 meaningful bigrams (i.e., collocations) must be included in the vocab using PMI measure.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Before loading data\n",
    "### Converting PDF to Excel\n",
    "\n",
    "The PDF data containing three columns namley, Title(unitname), Synopsis, and Outcome is converted to Excel format.\n",
    "The PDF to Excel conversion is done in using website https://simplypdf.com/Excel.\n",
    "    \n",
    "The xlsx file named 29915651.xlsx is loaded for further text processing\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4A. Examining and Loading data\n",
    "\n",
    "As a first step, the file 29915651.xlsx will be loaded so its first 10 lines can be inspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Outcomes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VPR2011</td>\n",
       "      <td>Research Practices Advanced is a core unit in ...</td>\n",
       "      <td>['Initiate a broad range of conceptual and ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VCO2304</td>\n",
       "      <td>This elective builds upon the core unit VCO130...</td>\n",
       "      <td>['Effectively use the elements and principles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FIT3176</td>\n",
       "      <td>This unit will introduce advanced concepts in ...</td>\n",
       "      <td>['design a database model from a given scenari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FIT5127</td>\n",
       "      <td>This unit is a research unit common to FIT Mas...</td>\n",
       "      <td>['design a rigorous Masters level research pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EAE3152</td>\n",
       "      <td>The motion of a density-stratified fluid in a ...</td>\n",
       "      <td>['Discuss the physical theory of the motion of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Title                                           Synopsis  \\\n",
       "0  VPR2011  Research Practices Advanced is a core unit in ...   \n",
       "1  VCO2304  This elective builds upon the core unit VCO130...   \n",
       "2  FIT3176  This unit will introduce advanced concepts in ...   \n",
       "3  FIT5127  This unit is a research unit common to FIT Mas...   \n",
       "4  EAE3152  The motion of a density-stratified fluid in a ...   \n",
       "\n",
       "                                            Outcomes  \n",
       "0  ['Initiate a broad range of conceptual and ana...  \n",
       "1  ['Effectively use the elements and principles ...  \n",
       "2  ['design a database model from a given scenari...  \n",
       "3  ['design a rigorous Masters level research pro...  \n",
       "4  ['Discuss the physical theory of the motion of...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('C:/Users/Stephy/Documents/Studies/Data Science 2018/Sem 2/Wrangling/Assignment1/James_29915651_Assig1/29915651.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197\n"
     ]
    }
   ],
   "source": [
    "type(data)\n",
    "\n",
    "#find the number of rows in dataframe\n",
    "data.shape[0] \n",
    "\n",
    "#count of rows in data\n",
    "rowcnt = data.shape[0]\n",
    "\n",
    "#extracting Title\n",
    "Title = data.Title[0:rowcnt]\n",
    "#Ref: https://stackoverflow.com/questions/15112234/how-can-i-convert-a-pandas-dataframe-into-a-list\n",
    "print(len(Title.unique())) #3 duplicated units\n",
    "\n",
    "#extracting Synopsis\n",
    "Synopsis = data.Synopsis[0:rowcnt]\n",
    "synopsis_list = list(Synopsis.values.flatten())\n",
    "\n",
    "#extracting Outcomes\n",
    "Outcomes = data.Outcomes[0:rowcnt]\n",
    "outcome_list = list(Outcomes.values.flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that there are 197 unique unit codes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4B. Methodology breif\n",
    "\n",
    "1. As okens must be normalized to lowercase except the capital tokens appeared in the middle of a sentence/line, the first step is to convert all the fisrt letter with capital first alphabets to lower case. This is done for both synopsis and outcome.\n",
    "\n",
    "2. In the second step both synopsis and outcome is combined as string corresponding to its unit code.\n",
    "\n",
    "3. The unit detail string composed of unit synopsis and unit outcome is tokenized.\n",
    "\n",
    "4. 200 Bigrams are generated from the tokenized content using PMI measure. \n",
    "\n",
    "5. The bigrams are then added to the unit content and the content is retokenized.\n",
    "\n",
    "6. The context independent stop words (from the stopword_en) are removed from the tokens.\n",
    "\n",
    "7. The context dependent stopwards are removed from the above tokens\n",
    "   It is done in three stages\n",
    "   a. Removal of words appearing in more than 95% document\n",
    "   b. Removal of words appearing in less than 5%document\n",
    "   c. Removal of word with length less than 3\n",
    "   \n",
    "8. Stemming is done using Porter Stem method.\n",
    "\n",
    "9. The vocab file inclusive of bigarms and unigrams is generated in the token_string:integer_index format.\n",
    "\n",
    "10. Sparse represenation of file is created in the format unit_code, token1_index:wordcount, token2_index:wordcount,...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Converting the first letter of each sentence to lower case \n",
    "\n",
    "Tokens need to be normalized to lowercase except the capital tokens appearing in the middle of a sentence/line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk.data\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "#the first word of each line/sentence is converted to lower case for synopsis\n",
    "#sent_detector.tokenize from nltk.data is used to extract sentences\n",
    "synopsis_new=[]\n",
    "for i in range (0,rowcnt): \n",
    "    raw_text = str(synopsis_list[i])\n",
    "    sentences = sent_detector.tokenize(raw_text.strip())\n",
    "    #newsent=[]\n",
    "    string = \"\"\n",
    "    for sent in sentences:\n",
    "        first_word=re.match('\\w*\\s?', sent)\n",
    "        #replace first occurance\n",
    "        sent  = sent.replace(first_word[0], first_word[0].lower(), 1)\n",
    "        string = string +\" \"+sent\n",
    "    #print(string)\n",
    "    synopsis_new.append(string)   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unit will cover the clinical and non-clinical topics listed below, enabling appropriate management of palliative care patients.\n",
      " the unit will cover the clinical and non-clinical topics listed below, enabling appropriate management of palliative care patients.\n"
     ]
    }
   ],
   "source": [
    "#checking if the new and old synopsis list is the same except for case change of first letter\n",
    "print(synopsis_list[199])\n",
    "print(synopsis_new[199])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in terms of lower case for first letter of a sentence can be observed for synopsis of the last unit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk.data\n",
    "#sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "#the first word of each line/sentence is converted to lower case for outcome\n",
    "#sent_detector.tokenize from nltk.data is used to extract sentences\n",
    "outcome_final =[]\n",
    "outcome_new=[]\n",
    "for i in range (rowcnt): \n",
    "    raw_text = str(outcome_list[i])\n",
    "    sentences = sent_detector.tokenize(raw_text.strip()) \n",
    "    for sent in sentences:\n",
    "        sent = sent.split(\"', '\")\n",
    "        each_line = \"\"\n",
    "        for each in sent:\n",
    "            each = each.replace(\"['\", \"\")\n",
    "            first_word=re.match('\\w*\\s?', each)\n",
    "            #print(each)\n",
    "            each  = each.replace(first_word[0], first_word[0].lower(), 1)\n",
    "            #each = each.strip()\n",
    "            each_line = each_line+\" \"+each\n",
    "            #print(each_line)\n",
    "        outcome_new.append(each_line)\n",
    "        outcome_new1 = ' '.join(outcome_new)\n",
    "        \n",
    "    outcome_final.append(outcome_new1)\n",
    "    outcome_new=[]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Integrate clinical assessments and patient history to develop evidence-based clinical management plans in palliative care.', 'Justify evidence based pharmacological recommendations relating to palliative care to healthcare consumers including patients, family members and multi-disciplinary healthcare professionals.', 'Recognise, monitor, and manage (pharmacologically and\n",
      "non-pharmacologically) symptoms and treatment side-effects common in palliative care.', 'Apply the principles of quality use of medicines in prescribing and de-prescribing in palliative care.', 'Critically reflect on their individual learning process and progress in clinical competence.']\n",
      " integrate clinical assessments and patient history to develop evidence-based clinical management plans in palliative care.   justify evidence based pharmacological recommendations relating to palliative care to healthcare consumers including patients, family members and multi-disciplinary healthcare professionals.   recognise, monitor, and manage (pharmacologically and\n",
      "non-pharmacologically) symptoms and treatment side-effects common in palliative care.   apply the principles of quality use of medicines in prescribing and de-prescribing in palliative care.   critically reflect on their individual learning process and progress in clinical competence.']\n"
     ]
    }
   ],
   "source": [
    "print(outcome_list[199])\n",
    "print(outcome_final[199])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in terms of lower case for first letter of a sentence can be observed for outcome fpr the last unit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Combining the outcome and synopsis list with title list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the unit will cover the clinical and non-clinical topics listed below, enabling appropriate management of palliative care patients.  integrate clinical assessments and patient history to develop evidence-based clinical management plans in palliative care.   justify evidence based pharmacological recommendations relating to palliative care to healthcare consumers including patients, family members and multi-disciplinary healthcare professionals.   recognise, monitor, and manage (pharmacologically and\n",
      "non-pharmacologically) symptoms and treatment side-effects common in palliative care.   apply the principles of quality use of medicines in prescribing and de-prescribing in palliative care.   critically reflect on their individual learning process and progress in clinical competence.']\n"
     ]
    }
   ],
   "source": [
    "#combining the outcome and synopsis list with title list\n",
    "unit_dtl={}\n",
    "\n",
    "for i in range(rowcnt):\n",
    "   \n",
    "    value = str(str(synopsis_new[i]) +\" \"+str(outcome_final[i]))\n",
    "    #key is unit_dtl[data.Title[i]]\n",
    "    unit_dtl[data.Title[i]] = value\n",
    "\n",
    "#checking for one unit\n",
    "print(unit_dtl['PGC5118'])\n",
    "\n",
    "#number of unique units \n",
    "len(unit_dtl.keys())\n",
    "\n",
    "unitcount = len(unit_dtl.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example of unit 'PGC5118' is used to explain how the synopsis and outcome of the unit is combined corresponding to it unit code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new dictionary with unit names and corresponding tokens\n",
    "#this dictionary will contain the unit id and its corresponding tokens\n",
    "unit_tokens  = {}\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "#pattern as specified in assignment\n",
    "tokenizer = RegexpTokenizer(r\"\\w+(?:[-']\\w+)?\")\n",
    "\n",
    "for i in range(rowcnt):\n",
    "    #text to be tokenized\n",
    "    raw_text = unit_dtl.get(Title[i])\n",
    "    unit_tokens[Title[i]] = tokenizer.tokenize(raw_text)\n",
    "\n",
    "#checking one unit \n",
    "print(unit_tokens['PGC5118'])\n",
    "\n",
    "#number of unique units \n",
    "len(unit_tokens.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the step before tokenization, one can observe the differnce between tokens and a normal string. Each word is separated as token using tokenizer = RegexpTokenizer(r\"\\w+(?:[-']\\w+)?\") from the RegexpTokenizer function of nltk.tokenize \n",
    "\n",
    "\"RegexpTokenizer splits a string into substrings using a regular expression. For example, the following tokenizer forms tokens out of alphabetic sequences, money expressions, and any other non-whitespace sequences\" - https://www.nltk.org/_modules/nltk/tokenize/regexp.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit id\t\tTokens#\n",
      "VPR2011 \t 186\n",
      "VCO2304 \t 126\n",
      "FIT3176 \t 55\n",
      "FIT5127 \t 69\n",
      "EAE3152 \t 65\n"
     ]
    }
   ],
   "source": [
    "print(\"Unit id\"+\"\\t\\t\"+\"Tokens#\")\n",
    "\n",
    "for i in range(0,5):\n",
    "    tokens=len(set(unit_tokens[Title[i]]))\n",
    "    tokens_flg=0\n",
    "    tokens_flg = tokens_flg+tokens\n",
    "    print(Title[i],\"\\t\" ,tokens_flg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of tokens corresponding to few units is mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  4098 \n",
      "Total number of tokens:  31470 \n",
      "Lexical diversity:  7.679355783308931\n"
     ]
    }
   ],
   "source": [
    "#Ref: Exploring Pre-Processed text and Generating Features Tutorial\n",
    "\n",
    "#The words and vocab checked\n",
    "words = list(chain.from_iterable(unit_tokens.values()))\n",
    "vocab = set(words)\n",
    "lexical_diversity = len(words)/len(vocab)\n",
    "print (\"Vocabulary size: \",len(vocab),\"\\nTotal number of tokens: \", len(words), \\\n",
    "\"\\nLexical diversity: \", lexical_diversity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.  Generating the 200 bigram collocations using PMI measure\n",
    "The next step is go generate the bigram collocations, given the tokenized unit information.\n",
    "\n",
    "The function BigramCollocationFinder.from_words() (NLTK Project, 2015) generate pairs of words that occur together. The apply_ngram_filter() (NLTK Project, 2015) is used to ensure no two stop words occur together.\n",
    "Additionally, bigrams can be filtered by their frequency using apply_freq_filter.\n",
    "\n",
    "PMI association measures the likelihood of two words occurring together given individual distributions in the corpus (Bouma, 2009).Lowering the frequency removes these obscure stop word pairs and by also using the PMI filter, new meaningful pairs with high scores can climb to the top results. \n",
    "\n",
    "In this case, bigrams with less than 3 occurrences and word length less than 3 are filtered while applying PMI at the same time.\n",
    "\n",
    "Reference for BigramCollocationFinder and PMI explanation: example_code_quality_comment_1 tutorial\n",
    "\n",
    "Steps:\n",
    "\n",
    "Step1:For this all the tokenized unit details are concatenated using the chain.frome_iterable function. A list containing a list of all the words seprated by while space is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['research', 'Practices', 'Advanced', 'is', 'a', 'core', 'unit', 'in', 'the', 'Visual']\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "all_words = list(chain.from_iterable(unit_tokens.values()))\n",
    "print(all_words[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: http://www.nltk.org/howto/collocations.html\n",
    "\n",
    "Step2: Generate the 200 bigram cllocations using\n",
    "* BigramAssocMeasures()\n",
    "* BigramCollocationFinder.from_words()\n",
    "* apply_freq_filter(20)\n",
    "* apply_word_filter(lambda w: len(w) < 3)\n",
    "* nbest(bigram_measures.pmi, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Daily', 'Living'),\n",
       " ('Living', 'Technologies'),\n",
       " ('Mobility', 'Augmentative'),\n",
       " ('New', 'Kingdom'),\n",
       " ('Organisational', 'Behaviour'),\n",
       " ('Positioning', 'Mobility'),\n",
       " ('bones', 'girdles'),\n",
       " ('digestive', 'urinary'),\n",
       " ('segmentation', 'targeting'),\n",
       " ('Alternative', 'Communication'),\n",
       " ('International', 'Relations'),\n",
       " ('travel', 'demand'),\n",
       " ('confidence', 'intervals'),\n",
       " ('Assistive', 'Technology'),\n",
       " ('Social', 'Workers'),\n",
       " ('Technology', 'Access'),\n",
       " ('long', 'bones'),\n",
       " ('lower', 'digestive'),\n",
       " ('lower', 'respiratory'),\n",
       " ('criminal', 'justice'),\n",
       " ('Additive', 'Manufacturing'),\n",
       " ('taxable', 'income'),\n",
       " ('additive', 'manufacturing'),\n",
       " ('lobby', 'groups'),\n",
       " ('metal', 'complexes'),\n",
       " ('gene', 'expression'),\n",
       " ('Information', 'Systems'),\n",
       " ('radiographic', 'images'),\n",
       " ('debt', 'instruments'),\n",
       " ('businesses', 'operating'),\n",
       " ('twentieth', 'century'),\n",
       " ('random', 'variables'),\n",
       " ('controlling', 'chosen'),\n",
       " ('South', 'African'),\n",
       " ('ideological', 'critiques'),\n",
       " ('pressure', 'injuries'),\n",
       " ('21st', 'century'),\n",
       " ('pressure', 'injury'),\n",
       " ('biological', 'hazards'),\n",
       " ('female', 'reproductive'),\n",
       " ('printed', 'part'),\n",
       " ('successful', 'completion'),\n",
       " ('Islamic', 'finance'),\n",
       " ('market', 'efficiency'),\n",
       " ('welfare', 'state'),\n",
       " ('community-based', 'emergency'),\n",
       " ('asset', 'pricing'),\n",
       " ('digital', 'humanities'),\n",
       " ('video', 'journalism'),\n",
       " ('current', 'affairs'),\n",
       " ('family', 'violence'),\n",
       " ('has', 'been'),\n",
       " ('service', 'delivery'),\n",
       " ('ART', 'laboratory'),\n",
       " ('polymeric', 'materials'),\n",
       " ('statistical', 'inference'),\n",
       " ('road', 'users'),\n",
       " ('relationship', 'breakdown'),\n",
       " ('Egyptian', 'culture'),\n",
       " ('custodial', 'setting'),\n",
       " ('activities', 'dealing'),\n",
       " ('consumer', 'behaviour'),\n",
       " ('decision', 'making'),\n",
       " ('chamber', 'music'),\n",
       " ('problem', 'solving'),\n",
       " ('performance', 'measurement'),\n",
       " ('food', 'security'),\n",
       " ('radiation', 'therapy'),\n",
       " ('urban', 'water'),\n",
       " ('interior', 'architecture'),\n",
       " ('aerospace', 'industry'),\n",
       " ('quality', 'improvement'),\n",
       " ('employ', 'occupational'),\n",
       " ('public', 'sector'),\n",
       " ('mass', 'media'),\n",
       " ('radiation', 'oncology'),\n",
       " ('women', 'during'),\n",
       " ('most', 'common'),\n",
       " ('individual', 'summative'),\n",
       " ('mix', 'elements'),\n",
       " ('own', 'capabilities'),\n",
       " ('welfare', 'trends'),\n",
       " ('real', 'world'),\n",
       " ('road', 'network'),\n",
       " ('corporate', 'finance'),\n",
       " ('positioning', 'strategy'),\n",
       " ('software', 'packages'),\n",
       " ('credit', 'risk'),\n",
       " ('digital', 'audio'),\n",
       " ('marketing', 'mix'),\n",
       " ('academic', 'staff'),\n",
       " ('trauma', 'context'),\n",
       " ('literary', 'texts'),\n",
       " ('assessment', 'task'),\n",
       " ('summative', 'assessment'),\n",
       " ('assistive', 'technology'),\n",
       " ('analytical', 'technique'),\n",
       " ('team', 'building'),\n",
       " ('link', 'between'),\n",
       " ('financial', 'disputes'),\n",
       " ('group', 'activities'),\n",
       " ('innovative', 'solutions'),\n",
       " ('dividend', 'policy'),\n",
       " ('case', 'studies'),\n",
       " ('insurance', 'law'),\n",
       " ('insights', 'into'),\n",
       " ('high', 'level'),\n",
       " ('distinguish', 'between'),\n",
       " ('capital', 'structure'),\n",
       " ('popular', 'music'),\n",
       " ('human', 'rights'),\n",
       " ('video', 'production'),\n",
       " ('food', 'product'),\n",
       " ('component', 'technologies'),\n",
       " ('analytical', 'method'),\n",
       " ('childhood', 'problems'),\n",
       " ('source', 'relevant'),\n",
       " ('professional', 'standards'),\n",
       " ('semi-structured', 'data'),\n",
       " ('palliative', 'care'),\n",
       " ('youth', 'care'),\n",
       " ('world', 'politics'),\n",
       " ('topics', 'covered'),\n",
       " ('drawn', 'from'),\n",
       " ('thinking', 'problem'),\n",
       " ('digital', 'spatial'),\n",
       " ('screen', 'practices'),\n",
       " ('particular', 'cases'),\n",
       " ('international', 'relations'),\n",
       " ('pricing', 'models'),\n",
       " ('computer', 'science'),\n",
       " ('environmental', 'sustainability'),\n",
       " ('methodological', 'approaches'),\n",
       " ('critical', 'dialogue'),\n",
       " ('further', 'developed'),\n",
       " ('assessment', 'tasks'),\n",
       " ('particular', 'reference'),\n",
       " ('financial', 'decisions'),\n",
       " ('data', 'collection'),\n",
       " ('wide', 'range'),\n",
       " ('mobile', 'applications'),\n",
       " ('global', 'welfare'),\n",
       " ('probability', 'theory'),\n",
       " ('statutory', 'principles'),\n",
       " ('data', 'handling'),\n",
       " ('global', 'politics'),\n",
       " ('clinical', 'reasoning'),\n",
       " ('communicate', 'effectively'),\n",
       " ('solve', 'problems'),\n",
       " ('taxation', 'law'),\n",
       " ('relationship', 'between'),\n",
       " ('subject', 'area'),\n",
       " ('fashion', 'theory'),\n",
       " ('finance', 'law'),\n",
       " ('have', 'been'),\n",
       " ('different', 'kinds'),\n",
       " ('critical', 'thinking'),\n",
       " ('that', 'underpin'),\n",
       " ('marketing', 'strategy'),\n",
       " ('common', 'law'),\n",
       " ('covered', 'include'),\n",
       " ('evidence', 'based'),\n",
       " ('broad', 'range'),\n",
       " ('road', 'system'),\n",
       " ('are', 'encouraged'),\n",
       " ('material', 'properties'),\n",
       " ('scientific', 'report'),\n",
       " ('chosen', 'marketing'),\n",
       " ('Australian', 'art'),\n",
       " ('spatial', 'data'),\n",
       " ('accounting', 'information'),\n",
       " ('reflect', 'upon'),\n",
       " ('mental', 'health'),\n",
       " ('topics', 'include'),\n",
       " ('comprehensive', 'understanding'),\n",
       " ('software', 'applications'),\n",
       " ('contemporary', 'discourse'),\n",
       " ('differentiate', 'between'),\n",
       " ('water', 'resources'),\n",
       " ('occupational', 'health'),\n",
       " ('safety', 'appropriate'),\n",
       " ('risk', 'factors'),\n",
       " ('oral', 'presentation'),\n",
       " ('particular', 'focus'),\n",
       " ('visual', 'art'),\n",
       " ('occupational', 'therapy'),\n",
       " ('structural', 'system'),\n",
       " ('discourse', 'analysis'),\n",
       " ('between', 'local'),\n",
       " ('market', 'information'),\n",
       " ('portfolio', 'theory'),\n",
       " ('financial', 'planning'),\n",
       " ('health', 'consumers'),\n",
       " ('but', 'also'),\n",
       " ('radiation', 'safety'),\n",
       " ('that', 'affect'),\n",
       " ('impact', 'upon'),\n",
       " ('management', 'accounting'),\n",
       " ('different', 'types'),\n",
       " ('risk', 'modelling')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ref: tutorial_05_answer\n",
    "    \n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "bigram_finder = nltk.collocations.BigramCollocationFinder.from_words(all_words)\n",
    "#ignoring all bigrams which occur less than three times \n",
    "bigram_finder.apply_freq_filter(3)\n",
    "#ignoring words which are less than 3 character in length to remove bigrams like ('n', 'nStudents')\n",
    "bigram_finder.apply_word_filter(lambda w: len(w) < 3)\n",
    "top_200_bigrams = bigram_finder.nbest(bigram_measures.pmi, 200) # Top-200 bigrams\n",
    "top_200_bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example of bigrams are mentioned in the above output.\n",
    "It is worthwhile to mention again that only meaningful bigrams have been connsidered by removing bigrams that occur less than 3 times and by removing bigrams with word length less than 3 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Re-tokenizing the unit details post finding bigrams\n",
    "In Section 7 the tokenization was done with only unigrams. \n",
    "In this steps the 200 meaningful bigrams are also introduced into the text to tokenzie with the bigrams\n",
    "The tokenizer used is MWEtokenizer.\n",
    "\n",
    "\"MWETokenizer takes a string which has already been divided into tokens and retokenizes it, merging multi-word expressions into single tokens, using a lexicon of MWEs\"\n",
    "Ref https://www.nltk.org/_modules/nltk/tokenize/mwe.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'unit', 'will', 'cover', 'the', 'clinical', 'and', 'non-clinical', 'topics', 'listed', 'below', 'enabling', 'appropriate', 'management', 'of', 'palliative', 'care', 'patients', 'integrate', 'clinical', 'assessments', 'and', 'patient', 'history', 'to', 'develop', 'evidence-based', 'clinical', 'management', 'plans', 'in', 'palliative', 'care', 'justify', 'evidence', 'based', 'pharmacological', 'recommendations', 'relating', 'to', 'palliative', 'care', 'to', 'healthcare', 'consumers', 'including', 'patients', 'family', 'members', 'and', 'multi-disciplinary', 'healthcare', 'professionals', 'recognise', 'monitor', 'and', 'manage', 'pharmacologically', 'and', 'non-pharmacologically', 'symptoms', 'and', 'treatment', 'side-effects', 'common', 'in', 'palliative', 'care', 'apply', 'the', 'principles', 'of', 'quality', 'use', 'of', 'medicines', 'in', 'prescribing', 'and', 'de-prescribing', 'in', 'palliative', 'care', 'critically', 'reflect', 'on', 'their', 'individual', 'learning', 'process', 'and', 'progress', 'in', 'clinical', 'competence']\n",
      "['the', 'unit', 'will', 'cover', 'the', 'clinical', 'and', 'non-clinical', 'topics', 'listed', 'below', 'enabling', 'appropriate', 'management', 'of', 'palliative_care', 'patients', 'integrate', 'clinical', 'assessments', 'and', 'patient', 'history', 'to', 'develop', 'evidence-based', 'clinical', 'management', 'plans', 'in', 'palliative_care', 'justify', 'evidence_based', 'pharmacological', 'recommendations', 'relating', 'to', 'palliative_care', 'to', 'healthcare', 'consumers', 'including', 'patients', 'family', 'members', 'and', 'multi-disciplinary', 'healthcare', 'professionals', 'recognise', 'monitor', 'and', 'manage', 'pharmacologically', 'and', 'non-pharmacologically', 'symptoms', 'and', 'treatment', 'side-effects', 'common', 'in', 'palliative_care', 'apply', 'the', 'principles', 'of', 'quality', 'use', 'of', 'medicines', 'in', 'prescribing', 'and', 'de-prescribing', 'in', 'palliative_care', 'critically', 'reflect', 'on', 'their', 'individual', 'learning', 'process', 'and', 'progress', 'in', 'clinical', 'competence']\n"
     ]
    }
   ],
   "source": [
    "#unit id with corresponding tokens inclusive of bigrams\n",
    "colloc_unit = {}\n",
    "\n",
    "from nltk.tokenize import MWETokenizer\n",
    "\n",
    "mwetokenizer = MWETokenizer(top_200_bigrams)\n",
    "colloc_unit =  dict((unit_id, mwetokenizer.tokenize(unit_content)) for unit_id,unit_content in unit_tokens.items())\n",
    "\n",
    "print(unit_tokens['PGC5118'])\n",
    "print(colloc_unit['PGC5118'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example of unit PGC5118 shows the difference between tokens wthout bigrams and with bigrams. Consider the words 'palliative', 'care' in the intianl list tokens. It has been changed to palliative_care post including bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit id\t\tTokens(including bigarms)#\n",
      "VPR2011 \t 184\n",
      "VCO2304 \t 123\n",
      "FIT3176 \t 55\n",
      "FIT5127 \t 67\n",
      "EAE3152 \t 64\n"
     ]
    }
   ],
   "source": [
    "print(\"Unit id\"+\"\\t\\t\"+\"Tokens(including bigarms)#\")\n",
    "\n",
    "for i in range(0,5):\n",
    "    tokens=len(set(colloc_unit[Title[i]]))\n",
    "    tokens_flg = 0\n",
    "    tokens_flg = tokens_flg+tokens\n",
    "    print(Title[i],\"\\t\" ,tokens_flg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size with bigram:  4242 \n",
      "Total number of tokens (with bigram):  30563\n"
     ]
    }
   ],
   "source": [
    "word_with_bigram = list(chain.from_iterable(colloc_unit.values()))\n",
    "vocab_with_bigram = list(set(word_with_bigram))\n",
    "lexical_diversity = len(word_with_bigram)/len(word_with_bigram)\n",
    "print (\"Vocabulary size with bigram: \",len(vocab_with_bigram),\"\\nTotal number of tokens (with bigram): \", len(word_with_bigram))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary size had increased, post inclusion of bigrams though the number of token has decreased to 30563"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Stop Words Removal\n",
    "\n",
    "Stop words carry little meaning with respect to text content; they are mostly supporting words such as articles, pronouns, etc.\n",
    "The context-independent and context-dependent (with the threshold set to %95) stop words need to be removed from the vocab.\n",
    "The stop words list (i.e, stopwords_en.txt) provided as per assignment guidelines is used.\n",
    "\n",
    "### 10A. Removing context independent words\n",
    "All the stopwords in the stopword file are context independent hence they are removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "a's\n",
      "able\n",
      "3588\n"
     ]
    }
   ],
   "source": [
    "stopwordfile = open(\"C:/Users/Stephy/Documents/Studies/Data Science 2018/Sem 2/Wrangling/Assignment1/James_29915651_Assig1/stopwords_en.txt\",'r')\n",
    "stopwords = stopwordfile.read()\n",
    "stopwordfile.close()\n",
    "\n",
    "print(stopwords[0:10])\n",
    "\n",
    "print(len(stopwords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stop words \n",
    "#From retokined dict (colloc_unit) in which bigrams have been included \n",
    "#For each word in unit_dtl value, keep the word if the word is not in the stopwordsSet\n",
    "unit_dtl_rsw = {}  \n",
    "for i in range(len(Title)):\n",
    "    unit_dtl_rsw[Title[i]] = [w for w in colloc_unit[Title[i]] if w not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size after removing stop words:  3958 \n",
      "Total number of tokens after removing stop words:  17810\n"
     ]
    }
   ],
   "source": [
    "words_rm_sw = list(chain.from_iterable(unit_dtl_rsw.values()))\n",
    "vocab_rm = set(words_rm_sw)\n",
    "print (\"Vocabulary size after removing stop words: \",len(vocab_rm),\"\\nTotal number of tokens after removing stop words: \", len(words_rm_sw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Vocab from unit content: 4098\n",
      "Vocab before removing stopwords(inclusive of bigrams): 4242\n",
      "Vocab after removing stopwords: 3958\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial Vocab from unit content:\",len(vocab))\n",
    "print(\"Vocab before removing stopwords(inclusive of bigrams):\",len(vocab_with_bigram))\n",
    "print(\"Vocab after removing stopwords:\",len(vocab_rm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10B.Removing context dependent words\n",
    "\n",
    "The context-dependent (with the threshold set to %95) of the document frequency needs to be removed. \n",
    "\n",
    "\"The FreqDist class is used to encode “frequency distributions”, which count the number of times that each outcome of an experiment occurs\"\n",
    "Ref http://www.nltk.org/api/nltk.html?highlight=freqdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unit', 268),\n",
       " ('students', 220),\n",
       " ('research', 200),\n",
       " ('design', 168),\n",
       " ('skills', 149),\n",
       " ('practice', 134),\n",
       " ('apply', 129),\n",
       " ('develop', 113),\n",
       " ('management', 111),\n",
       " ('demonstrate', 108)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploring common words\n",
    "from nltk.probability import *\n",
    "fd_1 = FreqDist(words_rm_sw)\n",
    "fd_1.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequencies of the 25 most common word in among all units is plotted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fd_1.plot(25, cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most frequent words in terms of document frequency needs to be calculated. \n",
    "The count of how many document a word appears in is calculated, this is referred to as document frequency\n",
    "FreqDist() jointly with set() is used for this purpose. \n",
    "\n",
    "1.Applying set() to each unit content to generate a set of unique words in a particular unit.\n",
    "The step is useful as it makes each word in a unit's content count only once\n",
    "\n",
    "2.The sets are then flattened using chain.from_iterable \n",
    "\n",
    "3.The list is passed through FreqDist\n",
    "The count of word from the list is equal to the number of documents containing that word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unit', 164),\n",
       " ('students', 113),\n",
       " ('skills', 89),\n",
       " ('apply', 87),\n",
       " ('analyse', 74),\n",
       " ('develop', 70),\n",
       " ('demonstrate', 70),\n",
       " ('evaluate', 70),\n",
       " ('identify', 67),\n",
       " ('knowledge', 65)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying set() to each unit content to generate a set of unique words in a particular unit \n",
    "#and save all sets in a list\n",
    "\n",
    "uniq_in_unit = list(chain.from_iterable([set(value) for value in unit_dtl_rsw.values()]))\n",
    "fd_2 = FreqDist(uniq_in_unit)\n",
    "fd_2.most_common(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be concluded that the word 'unit' appears across 164 units, 'students' across 113 units and so on.\n",
    "Now the words appearing in more than 95% of the units need to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190.0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#removing words that repeat in more than 95% of the documents\n",
    "#maximun number of words unique in the documment = 3958\n",
    "#all words with frequency\n",
    "word_list = list(fd_2.most_common(3958))\n",
    "\n",
    "#95% of the document size:\n",
    "upper_limit = .95*rowcnt\n",
    "print(upper_limit)\n",
    "\n",
    "#making a list of words appearing in more that 95% document to use as stop words\n",
    "upper_words=[]\n",
    "for word in word_list:\n",
    "    if word[1]>upper_limit:\n",
    "        upper_words.append(word[0])\n",
    "\n",
    "print(upper_words)        \n",
    "\n",
    "upper_removed={}\n",
    "for i in range(rowcnt):\n",
    "    upper_removed[Title[i]]= [w for w in unit_dtl_rsw[Title[i]] if w not in upper_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size after removing words appearing in more than 95% documents:  3958 \n",
      "Total number of tokens after removing words appearing in more than 95% documents :  17810\n"
     ]
    }
   ],
   "source": [
    "words_upp_rm = list(chain.from_iterable(upper_removed.values()))\n",
    "vocab_upp_rm = set(words_upp_rm)\n",
    "print (\"Vocabulary size after removing words appearing in more than 95% documents: \",len(vocab_upp_rm),\"\\nTotal number of tokens after removing words appearing in more than 95% documents : \", len(words_upp_rm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10C. Removing rare tokens (with the threshold set to %5) from the vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "['aim', 'develops', 'making', 'create', 'acquired', 'relationship_between', 'introduce', 'reference', 'important', 'influence']\n"
     ]
    }
   ],
   "source": [
    "#5% of the document size:\n",
    "lower_limit = .05*rowcnt\n",
    "print(lower_limit)\n",
    "\n",
    "\n",
    "#making a list of words appearing in less that 5% document to use as stop words\n",
    "lower_words=[]\n",
    "for word in word_list:\n",
    "    if word[1]<lower_limit:\n",
    "        lower_words.append(word[0])\n",
    "        \n",
    "print(lower_words[0:10])\n",
    "        \n",
    "lower_removed={}\n",
    "for i in range(rowcnt):\n",
    "    lower_removed[Title[i]]= [w for w in upper_removed[Title[i]] if w not in lower_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of tokens apprearing in less than 5% documents is very large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size after removing words appearing in less than 5% documents:  261 \n",
      "Total number of tokens after removing words appearing in less than 5% documents :  8302\n"
     ]
    }
   ],
   "source": [
    "words_low_rm = list(chain.from_iterable(lower_removed.values()))\n",
    "vocab_low_rm = set(words_low_rm)\n",
    "print (\"Vocabulary size after removing words appearing in less than 5% documents: \",len(vocab_low_rm),\n",
    "       \"\\nTotal number of tokens after removing words appearing in less than 5% documents : \", len(words_low_rm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10D. Removing tokens with the length less than 3 from the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', 'IT', '3D', '1', '3', 'CT', 'AM', 'A', 'E', 'R', 'OS', 'NH', 'TV', '8', 'LF', '15', '20', 'B', '3B', '3A', '3d', '70', 'I', 'II', 'nb', '4', 'A2', 'pH', 'OD']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#making a list of words appearing in less that 5% document to use as stop words\n",
    "small_words=[]\n",
    "for word in word_list:\n",
    "    if len(word[0])<3:\n",
    "        small_words.append(word[0])\n",
    "        \n",
    "print(small_words)\n",
    "        \n",
    "small_removed={}\n",
    "for i in range(rowcnt):\n",
    "    small_removed[Title[i]]= [w for w in lower_removed[Title[i]] if w not in small_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size after removing words appearing in less than 5% documents:  261 \n",
      "Total number of tokens after removing words appearing in less than 5% documents :  8302\n"
     ]
    }
   ],
   "source": [
    "words_sml_rm = list(chain.from_iterable(small_removed.values()))\n",
    "vocab_sml_rm = set(words_sml_rm)\n",
    "print (\"Vocabulary size after removing words appearing in less than 5% documents: \",len(vocab_sml_rm),\n",
    "       \"\\nTotal number of tokens after removing words appearing in less than 5% documents : \", len(words_sml_rm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.Stemming using the Porter stemmer\n",
    "\n",
    "Stemming helps to reduce the same word in different lexical forms to its base form. For example verbs are written in the various tenses but the base word remains same. The same applies to nouns, adjectives or any other form of word. \n",
    "\n",
    "The bigrams have been included in the text so as to preserve meaning, hence it is desired to keep the bigram in its original state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list of bigrams so that the words can be excluded from stemming\n",
    "bigrams_words=[]\n",
    "\n",
    "#bigram list\n",
    "top_200_bigrams\n",
    "\n",
    "#length of bigram list\n",
    "x = len(top_200_bigrams)\n",
    "\n",
    "#converting bigram to the same format as in the token list\n",
    "for i in range(x):\n",
    "    bigrams_words.append(top_200_bigrams[i][0]+\"_\"+top_200_bigrams[i][1])\n",
    "\n",
    "\n",
    "#dictionary of bigrams with corresponding units\n",
    "bigrams={}\n",
    "for i in range(rowcnt):\n",
    "    bigrams[Title[i]]= [w for w in small_removed[Title[i]] if w in bigrams_words]\n",
    "\n",
    "#dictionary of tokens with corresponding units, without bigrams\n",
    "#used to stem\n",
    "bigrams_removed={}\n",
    "for i in range(rowcnt):\n",
    "    bigrams_removed[Title[i]]= [w for w in small_removed[Title[i]] if w not in bigrams_words]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unit',\n",
       " 'clinic',\n",
       " 'topic',\n",
       " 'manag',\n",
       " 'integr',\n",
       " 'clinic',\n",
       " 'patient',\n",
       " 'histori',\n",
       " 'develop',\n",
       " 'clinic',\n",
       " 'manag',\n",
       " 'relat',\n",
       " 'includ',\n",
       " 'recognis',\n",
       " 'manag',\n",
       " 'treatment',\n",
       " 'common',\n",
       " 'appli',\n",
       " 'principl',\n",
       " 'qualiti',\n",
       " 'critic',\n",
       " 'reflect',\n",
       " 'individu',\n",
       " 'learn',\n",
       " 'process',\n",
       " 'clinic']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing coresponding modules\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "final_tokens ={}\n",
    "\n",
    "#stemming tokens for corresponding units\n",
    "for i in range(rowcnt):\n",
    "    stemmed_tokens=[]\n",
    "    for tokens in bigrams_removed[Title[i]]:\n",
    "        stemmed_tokens.append(stemmer.stem(tokens))\n",
    "    final_tokens[Title[i]]=stemmed_tokens\n",
    "\n",
    "\n",
    "final_tokens['PGC5118']\n",
    "                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final token in PGC5118 has significantly decreased, post all the opeartions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the bigrams back to the stemmed results\n",
    "for i in range(rowcnt):\n",
    "    final_tokens[Title[i]] = final_tokens[Title[i]]+bigrams[Title[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_tokens.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Vocab text preparation in the token_string:integer_index format\n",
    "\n",
    "The words in the vocabulary needs to be sorted alphabetically and the unigrams and bigrams need to represented in token_string:integer_index format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating vocab file\n",
    "vocab_file = open(\"29915651_vocab.txt\",'w')\n",
    "\n",
    "#creating list of all the final tokens post duplicate removal and sorting\n",
    "all_final_tokens= sorted(list(set(list(chain.from_iterable(final_tokens.values())))))\n",
    "\n",
    "#saving into file as token_string:integer_index\n",
    "i = 0\n",
    "for token in all_final_tokens:\n",
    "    vocab_file.write((token)+\":\"+str(i)+\"\\n\")\n",
    "    i=i+1\n",
    "vocab_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_final_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Unit vocab report with token index and token frequency count\n",
    "The final output needs to be in \"unit_code, token1_index:wordcount, token2_index:wordcount,...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dict={}\n",
    "for i in range(len(all_final_tokens)):\n",
    "    index_dict[all_final_tokens[i]]=i\n",
    "#print(index_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file= open(\"29915651_countVec.txt\",'w')\n",
    "#vocab = list(vocab) #all_final_tokens\n",
    "\n",
    "#saving the tokens post counting frequency with its index number and with its unit code\n",
    "for k1,v1 in final_tokens.items():\n",
    "    d_idx = [index_dict[w] for w in v1]\n",
    "    out_file.write(\"{}, \".format(k1))\n",
    "    for k2, v2 in FreqDist(d_idx).items():\n",
    "        out_file.write(\"{}:{} ,\".format(k2,v2))\n",
    "    out_file.write('\\n')\n",
    "out_file.close()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.Summary \n",
    "\n",
    "This assessment helps in understanding next steps for analyzing textual data post extraction of text, i.e., converting the extracted data into a proper format The main outcomes achieved while applying these techniques were:\n",
    "\n",
    "- **Execution flow** to understand the importance of the order of execution for tokenization, finding bigrams, normalization, stemming etc. to retain the important words\n",
    "- **Tokenization, collocation extraction**. By using the `nltk` package charaters were tokeinzed with ease and 200 meaningful bigrams were also generated to further tokenize the initial corpus. \n",
    "- **Stopwaord Removal** the context dependent and context independent stopwards were easily removed using dictionary datatype\n",
    "- **Stemming** Stemming was carried out using Porter stem method to remove redundant information occurning due to lexical variations of the words.\n",
    "- **Vocabulary and sparse vector generation**. A vocabulary covering words from all units was obtained.`nltk`'s frequency distribution function `FreqDist()` were used to create the final sparese vector by counting the frequency of vocabulary word occurrences in each unit and representing the unit with its index.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. References\n",
    "\n",
    "To convert PDF to excel <br />\n",
    "https://simplypdf.com/Excel <br />\n",
    "Data frame to list <br />\n",
    "https://stackoverflow.com/questions/15112234/how-can-i-convert-a-pandas-dataframe-into-a-list <br />\n",
    "RegexpTokenizer <br />\n",
    "https://www.nltk.org/_modules/nltk/tokenize/regexp.html <br />\n",
    "Collocations <br />\n",
    "http://www.nltk.org/howto/collocations.html <br />\n",
    "MWETokenizer <br />\n",
    "https://www.nltk.org/_modules/nltk/tokenize/mwe.html <br />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
